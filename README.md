# Natural Language Inference as a Judge: Detecting Factuality and Causality Issues in Language Model Self-Reasoning for Financial Analysis
## Abstract
Language models (LMs) have revolutionized financial analysis by demonstrating expert-level versatility. Recent advances in self-reasoning have further improved LMs' performance on complex tasks. However, LMs are known to hallucinate facts and generate non-causal reasoning paths, which compromise their output quality, lead to erroneous conclusions, and pose risks of monetary losses. Therefore, detecting factual and causal errors in LMs' reasoning is essential for risk management and responsible application of LMs in finance. In this study, we adopt natural language inference (NLI) as a paradigm for detecting factual and causal errors in LMs' reasoning. We evaluate this approach by constructing a dataset comprising financial reasoning points generated by LMs, along with annotations by domain experts. Our findings demonstrate that NLI, powered by backbones of either pre-trained encoders or LMs, exhibits statistically significant capability in detecting factual and causal issues. Also, we show that, although LMs achieve improved performance with increasing parameters, they underperform encoders and exhibit self-evaluation bias in certain scenarios. Fine-tuning effectively mitigates this type of bias and enhances both backbones' detection ability.
> ### Please read our [article](https://arxiv.org/abs/) for further information.

## Dataset
`data` stores the three-fold split of samples for factuality and causality detection
- `factuality_fold_1.csv`, `factuality_fold_2.csv`, and `factuality_fold_3.csv` store the 1st, 2nd, and 3rd folds of factuality detection, respectively. The premise corresponds to the input information and the hypothesis is each reasoning statement. Label contains two types of contradiction and entailment.
- `causality_fold_1.csv`, `causality_fold_2.csv`, and `causality_fold_3.csv` store the 1st, 2nd, and 3rd folds of causality detection, respectively. The premise is the reasoning statement and the hypothesis is the classification outcome. Label contains two types of contradiction and entailment.
## Code
- `NLI-as-a-judge.ipynb` records the pre-trained performance of DeBERTa as an example of using the NLI paradigm to detect factual and causal errors in language model self-reasoning content.
- `Backbones.ipynb` compares the detection capability of factual errors across diverse pre-trained backbones using the NLI paradigm.
- `Fine-tuning.ipynb` compares the detection capabilities of pre-trained and fine-tuned versions of DeBERTa in identifying factual and causal errors, demonstrating that fine-tuning significantly enhances model performance, as evidenced by improved p-value significance levels.
- `Self-evaluation bias.ipynb` compares the self-evaluation bias of pre-trained and fine-tuned versions of Gemma-2-2B, demonstrating that fine-tuning significantly mitigates the model's self-evaluation bias, as evidenced by increased p-values indicating a reduced tendency to trust erroneous statements generated by itself.
## Citation
- Yilin Wu, Han Yuan, Li Zhang, Zheng Ma. Natural Language Inference as a Judge: Detecting Factuality and Causality Issues in Language Model Self-Reasoning for Financial Analysis. Proceedings of the Tenth Workshop on Financial Technology and Natural Language Processing.
